{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    100\n",
      "1    200\n",
      "2    300\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "my_labels = ['X','Y','Z']\n",
    "my_data = [100,200,300]\n",
    "\n",
    "# Converting my_data (Python list) to pandas Series\n",
    "print(pd.Series(data = my_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X    100\n",
      "Y    200\n",
      "Z    300\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(data = my_data, index = my_labels))\n",
    "#pd.Series(my_data, my_labels) \n",
    "# Same as above!, data and index are in order￿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X    100\n",
      "Y    200\n",
      "Z    300\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's create NumPy array from my_data and then Series from that array \n",
    "my_array = np.array(my_data) # creating numpy's array from list \n",
    "series = pd.Series(data = my_array, index = my_labels) # creating Series from numpy's array\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    X\n",
      "1    Y\n",
      "2    Z\n",
      "dtype: object\n",
      "0      <built-in function min>\n",
      "1      <built-in function max>\n",
      "2      <built-in function sum>\n",
      "3    <built-in function print>\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Let's pass my_labels (which is a list of strings) as data now! \n",
    "print(pd.Series(data = my_labels)) # passing list for strings as data\n",
    "\n",
    "# We can pass a list of built-in functions!\n",
    "print(pd.Series([min, max, sum, print]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating three dictionaries dict_1, dict_2, dict_3\n",
    "dict_1 = {'Toronto': 500, 'Calgary': 200, 'Vancouver': 300, 'Montreal': 700}\n",
    "dict_2 = {'Calgary': 200, 'Vancouver': 300, 'Montreal': 700}\n",
    "dict_3 = {'Calgary': 200, 'Vancouver': 300, 'Montreal': 700, 'Jasper':1000}\n",
    "\n",
    "# Creating Pandas Series from the dictionaries\n",
    "ser1 = pd.Series(dict_1)\n",
    "ser2 = pd.Series(dict_2)\n",
    "ser3 = pd.Series(dict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series 1 : \n",
      " Toronto      500\n",
      "Calgary      200\n",
      "Vancouver    300\n",
      "Montreal     700\n",
      "dtype: int64\n",
      "\n",
      "Series 2 : \n",
      " Calgary      200\n",
      "Vancouver    300\n",
      "Montreal     700\n",
      "dtype: int64\n",
      "\n",
      "Series 3 : \n",
      " Calgary       200\n",
      "Vancouver     300\n",
      "Montreal      700\n",
      "Jasper       1000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Series 1 : \\n\",ser1)\n",
    "print(\"\\nSeries 2 : \\n\",ser2)\n",
    "print(\"\\nSeries 3 : \\n\",ser3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calgary       400.0\n",
      "Montreal     1400.0\n",
      "Toronto         NaN\n",
      "Vancouver     600.0\n",
      "dtype: float64\n",
      "\n",
      "Calgary       600.0\n",
      "Jasper          NaN\n",
      "Montreal     2100.0\n",
      "Toronto         NaN\n",
      "Vancouver     900.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ser4 = ser1 + ser2 \n",
    "# adding Series and assigning/passing results to a new variable ser4\n",
    "print(ser4)\n",
    "print()\n",
    "# What if we add ser4 and ser3, another NaN for Jasper!\n",
    "ser5 = ser4 + ser3\n",
    "print(ser5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r1', 'r2', 'r3', 'r4', 'r5', 'r6', 'r7', 'r8', 'r9', 'r10']\n",
      "['c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10']\n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39]\n",
      " [40 41 42 43 44 45 46 47 48 49]\n",
      " [50 51 52 53 54 55 56 57 58 59]\n",
      " [60 61 62 63 64 65 66 67 68 69]\n",
      " [70 71 72 73 74 75 76 77 78 79]\n",
      " [80 81 82 83 84 85 86 87 88 89]\n",
      " [90 91 92 93 94 95 96 97 98 99]]\n"
     ]
    }
   ],
   "source": [
    "index = 'r1 r2 r3 r4 r5 r6 r7 r8 r9 r10'.split()\n",
    "columns = 'c1 c2 c3 c4 c5 c6 c7 c8 c9 c10'.split()\n",
    "# just to see what the index looks like, a list from r1 to r10!\n",
    "print(index)\n",
    "\n",
    "# and what columns look like, a list from c1 to c10!\n",
    "print(columns)\n",
    "\n",
    "array_2d = np.arange(0,100).reshape(10,10) # creating a 2D array \"array_2d\"\n",
    "print(array_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     c1  c2  c3  c4  c5  c6  c7  c8  c9  c10\n",
      "r1    0   1   2   3   4   5   6   7   8    9\n",
      "r2   10  11  12  13  14  15  16  17  18   19\n",
      "r3   20  21  22  23  24  25  26  27  28   29\n",
      "r4   30  31  32  33  34  35  36  37  38   39\n",
      "r5   40  41  42  43  44  45  46  47  48   49\n",
      "r6   50  51  52  53  54  55  56  57  58   59\n",
      "r7   60  61  62  63  64  65  66  67  68   69\n",
      "r8   70  71  72  73  74  75  76  77  78   79\n",
      "r9   80  81  82  83  84  85  86  87  88   89\n",
      "r10  90  91  92  93  94  95  96  97  98   99\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data = array_2d, index = index, columns = columns)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column C1 : \n",
      " r1      0\n",
      "r2     10\n",
      "r3     20\n",
      "r4     30\n",
      "r5     40\n",
      "r6     50\n",
      "r7     60\n",
      "r8     70\n",
      "r9     80\n",
      "r10    90\n",
      "Name: c1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Grabbing a single column\n",
    "print(\"Column C1 : \\n\", df['c1'])#It's a pada series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     c1  c2  c3  c4  c5  c6  c7  c8  c9  c10  new\n",
      "r1    0   1   2   3   4   5   6   7   8    9    1\n",
      "r2   10  11  12  13  14  15  16  17  18   19   21\n",
      "r3   20  21  22  23  24  25  26  27  28   29   41\n",
      "r4   30  31  32  33  34  35  36  37  38   39   61\n",
      "r5   40  41  42  43  44  45  46  47  48   49   81\n",
      "r6   50  51  52  53  54  55  56  57  58   59  101\n",
      "r7   60  61  62  63  64  65  66  67  68   69  121\n",
      "r8   70  71  72  73  74  75  76  77  78   79  141\n",
      "r9   80  81  82  83  84  85  86  87  88   89  161\n",
      "r10  90  91  92  93  94  95  96  97  98   99  181\n"
     ]
    }
   ],
   "source": [
    "df['new'] = df['c1'] + df['c2'] \n",
    "# adding a column \"new\" which is sum of \"c1\" and \"c2\"\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     c2  c3  c4  c5  c6  c7  c8  c9  c10  new\n",
      "r1    1   2   3   4   5   6   7   8    9    1\n",
      "r2   11  12  13  14  15  16  17  18   19   21\n",
      "r3   21  22  23  24  25  26  27  28   29   41\n",
      "r4   31  32  33  34  35  36  37  38   39   61\n",
      "r5   41  42  43  44  45  46  47  48   49   81\n",
      "r6   51  52  53  54  55  56  57  58   59  101\n",
      "r7   61  62  63  64  65  66  67  68   69  121\n",
      "r8   71  72  73  74  75  76  77  78   79  141\n",
      "r9   81  82  83  84  85  86  87  88   89  161\n",
      "r10  91  92  93  94  95  96  97  98   99  181\n"
     ]
    }
   ],
   "source": [
    "df.drop(['c1'], axis = 1, inplace = True) \n",
    "# If we don't pass inplace = True, then change will not be permanent\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    c2  c3  c4  c5  c6  c7  c8  c9  c10  new\n",
      "r2  11  12  13  14  15  16  17  18   19   21\n",
      "r3  21  22  23  24  25  26  27  28   29   41\n"
     ]
    }
   ],
   "source": [
    "# using loc, this will return rows r2 and r3,\n",
    "# notice the list [r2, r3] in square ,!brackets\n",
    "print(df.loc[['r2', 'r3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     c2  c3  c4  c5  c6  c7  c8  c9  c10  new\n",
      "r1    1   2   3   4   5   6   7   8    9    1\n",
      "r2   11  12  13  14  15  16  17  18   19   21\n",
      "r3   21  22  23  24  25  26  27  28   29   41\n",
      "r4   31  32  33  34  35  36  37  38   39   61\n",
      "r5   41  42  43  44  45  46  47  48   49   81\n",
      "r6   51  52  53  54  55  56  57  58   59  101\n",
      "r7   61  62  63  64  65  66  67  68   69  121\n",
      "r8   71  72  73  74  75  76  77  78   79  141\n",
      "r9   81  82  83  84  85  86  87  88   89  161\n",
      "r10  91  92  93  94  95  96  97  98   99  181\n",
      "Element at r1,c2 :  1\n",
      "Element at r2,c10 :  19\n",
      "Subset \n",
      "     c4  c2\n",
      "r1   3   1\n",
      "r2  13  11\n",
      "Random Columns and Rows \n",
      "     c3  c4\n",
      "r2  12  13\n",
      "r5  42  43\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "print(\"Element at r1,c2 : \", df.loc['r1','c2'])\n",
    "print(\"Element at r2,c10 : \", df.loc['r2', 'c10'])\n",
    "\n",
    "# for a subset, pass the list\n",
    "print(\"Subset \\n\",df.loc[['r1','r2'],['c4','c2']])\n",
    "\n",
    "# another example - random columns and rows in the list\n",
    "print(\"Random Columns and Rows \\n\", df.loc[['r2','r5'],['c3','c4']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herarchial Indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a  1    0.496714\n",
      "   2   -0.138264\n",
      "   3    0.647689\n",
      "b  1    1.523030\n",
      "   2   -0.234153\n",
      "   3   -0.234137\n",
      "c  1    1.579213\n",
      "   2    0.767435\n",
      "d  1   -0.469474\n",
      "   2    0.542560\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Importing numpy and Pandas first\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)  # You can use any integer as the seed value\n",
    "\n",
    "# Create a Series with a list of lists (or arrays) as the index: \n",
    "index = [['a','a','a','b','b','b','c','c','d','d'], # level 1 index \n",
    "         [1,2,3,1,2,3,1,2,1,2]] # level 2 index\n",
    "\n",
    "# Let's create a Series \"ser\" with multi-level index (2 in this example)\n",
    "ser = pd.Series(np.random.randn(10), index=index)\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe \n",
      " L_1  L_2\n",
      "a    1      0.496714\n",
      "     2     -0.138264\n",
      "     3      0.647689\n",
      "b    1      1.523030\n",
      "     2     -0.234153\n",
      "     3     -0.234137\n",
      "c    1      1.579213\n",
      "     2      0.767435\n",
      "d    1     -0.469474\n",
      "     2      0.542560\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ser.index.names = ['L_1', 'L_2']\n",
    "print(\"Dataframe \\n\", ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_2\n",
      "1    0.496714\n",
      "2   -0.138264\n",
      "3    0.647689\n",
      "dtype: float64\n",
      "L_1\n",
      "a    0.496714\n",
      "b    1.523030\n",
      "c    1.579213\n",
      "d   -0.469474\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Returns a cross-section (row(s) or column(s)) from the Series/DataFrame.\n",
    "print(ser.xs('a'))\n",
    "\n",
    "print(ser.xs(1, level='L_2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A   B   C     D\n",
      "0  1.0 NaN  11  16.0\n",
      "1  2.0 NaN  12   NaN\n",
      "2  NaN NaN  13  18.0\n",
      "3  4.0 NaN  14  19.0\n",
      "4  NaN NaN  15  20.0\n"
     ]
    }
   ],
   "source": [
    "# Creating a data dictionary\n",
    "data_dict = {'A':[1,2,np.nan,4,np.nan],\n",
    "            'B':[np.nan,np.nan,np.nan,np.nan,np.nan],\n",
    "            'C':[11,12,13,14,15],\n",
    "            'D':[16,np.nan,18,19,20]}\n",
    "# Creating DataFrame form data_dict\n",
    "df = pd.DataFrame(data_dict) # DataFrame from a dic.\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A     B      C      D\n",
      "0  False  True  False  False\n",
      "1  False  True  False   True\n",
      "2   True  True  False  False\n",
      "3  False  True  False  False\n",
      "4   True  True  False  False\n",
      "\n",
      "       A      B     C      D\n",
      "0   True  False  True   True\n",
      "1   True  False  True  False\n",
      "2  False  False  True   True\n",
      "3   True  False  True   True\n",
      "4  False  False  True   True\n"
     ]
    }
   ],
   "source": [
    "# isnull() returns True if the data is missing\n",
    "print(df.isnull())\n",
    "print()\n",
    "# notnull() returns True for non-NaN values\n",
    "print(df.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    2.0\n",
      "2    NaN\n",
      "3    4.0\n",
      "4    NaN\n",
      "Name: A, dtype: float64\n",
      "Sum :  7.0\n"
     ]
    }
   ],
   "source": [
    "# Sum on Column \"A\", (NaN as 0)\n",
    "print(df['A'])\n",
    "print(\"Sum : \", df['A'].sum())\n",
    "# grabbing column 'A' and calling sum() ==> 1.0+2.0+NaN(0)+4.0+NaN(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining and Merging Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe 1\n",
      "   key  A1  B1\n",
      "0   a   0   5\n",
      "1   b   1   6\n",
      "2   c   2   7\n",
      "3   d   3   8\n",
      "4   e   4   9\n",
      "Dataframe 2\n",
      "   key  A2  B2\n",
      "0   a   0   3\n",
      "1   b   1   4\n",
      "2   c   2   5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df1 = pd.DataFrame({'key': ['a', 'b', 'c', 'd', 'e'],'A1': range(5), 'B1':range(5,10)})\n",
    "df2 = pd.DataFrame({'key': ['a', 'b', 'c'], 'A2': range(3), 'B2':range(3,6)})\n",
    "print(\"Dataframe 1\\n\", df1)\n",
    "print(\"Dataframe 2\\n\", df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The how method tells merge() what type of joining operation needs to be done. The joining operation could be inner, outer, left, or right. The default value of how is inner.\n",
    "The on method specifies what field name to join on. This could be a label or a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "merged (how = 'inner'): \n",
      "   key  A1  B1  A2  B2\n",
      "0   a   0   5   0   3\n",
      "1   b   1   6   1   4\n",
      "2   c   2   7   2   5\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nmerged (how = 'inner'): \\n\",pd.merge(df1, df2, how = 'inner', on='key'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "merged (how = 'outer'): \n",
      "   key  A1  B1   A2   B2\n",
      "0   a   0   5  0.0  3.0\n",
      "1   b   1   6  1.0  4.0\n",
      "2   c   2   7  2.0  5.0\n",
      "3   d   3   8  NaN  NaN\n",
      "4   e   4   9  NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nmerged (how = 'outer'): \\n\",pd.merge(df1, df2, how = 'outer', on='key'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left is :\n",
      "   key1 key2   A   B\n",
      "0    a    a  A0  B0\n",
      "1    a    b  A1  B1\n",
      "2    b    a  A2  B2\n",
      "3    c    b  A3  B3\n",
      "\n",
      "right is :\n",
      "   key1 key2   C   D\n",
      "0    a    a  C0  D0\n",
      "1    b    b  C1  D1\n",
      "2    b    a  C2  D2\n",
      "3    c    a  C3  D3\n",
      "\n",
      "merged (inner) on key1 and key2 is :\n",
      "   key1 key2   A   B   C   D\n",
      "0    a    a  A0  B0  C0  D0\n",
      "1    b    a  A2  B2  C2  D2\n"
     ]
    }
   ],
   "source": [
    "# creating two DataFrames, left and right\n",
    "left = pd.DataFrame({'key1': ['a', 'a', 'b', 'c'],\n",
    "                     'key2': ['a', 'b', 'a', 'b'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "    \n",
    "right = pd.DataFrame({'key1': ['a', 'b', 'b', 'c'],\n",
    "                      'key2': ['a', 'b', 'a', 'a'],\n",
    "                      'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "print(\"left is :\\n\", left)\n",
    "print(\"\\nright is :\\n\",right)\n",
    "print(\"\\nmerged (inner) on key1 and key2 is :\\n\",pd.merge(left, right, how = 'inner', on=['key1', 'key2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left is :\n",
      "   key1 key2   A   B\n",
      "0    a    a  A0  B0\n",
      "1    a    b  A1  B1\n",
      "2    b    a  A2  B2\n",
      "3    c    b  A3  B3\n",
      "\n",
      "right is :\n",
      "   key1 key2   C   D\n",
      "0    a    a  C0  D0\n",
      "1    b    b  C1  D1\n",
      "2    b    a  C2  D2\n",
      "3    c    a  C3  D3\n",
      "\n",
      "merged (inner) on key1 and key2 is :\n",
      "   key1 key2   A   B   C   D\n",
      "0    a    a  A0  B0  C0  D0\n",
      "1    b    a  A2  B2  C2  D2\n"
     ]
    }
   ],
   "source": [
    "# creating two DataFrames, left and right\n",
    "left = pd.DataFrame({'key1': ['a', 'a', 'b', 'c'],\n",
    "                     'key2': ['a', 'b', 'a', 'b'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "    \n",
    "right = pd.DataFrame({'key1': ['a', 'b', 'b', 'c'],\n",
    "                      'key2': ['a', 'b', 'a', 'a'],\n",
    "                      'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "print(\"left is :\\n\", left)\n",
    "print(\"\\nright is :\\n\",right)\n",
    "print(\"\\nmerged (inner) on key1 and key2 is :\\n\",pd.merge(left, right, how = 'inner', on=['key1', 'key2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "merged (outer) on key1 and key2 is :\n",
      "   key1 key2    A    B    C    D\n",
      "0    a    a   A0   B0   C0   D0\n",
      "1    a    b   A1   B1  NaN  NaN\n",
      "2    b    a   A2   B2   C2   D2\n",
      "3    c    b   A3   B3  NaN  NaN\n",
      "4    b    b  NaN  NaN   C1   D1\n",
      "5    c    a  NaN  NaN   C3   D3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nmerged (outer) on key1 and key2 is :\\n\", pd.merge(left, right, how='outer', on=['key1', 'key2']))\n",
    "# notice NaN for the missing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation is an operation that glues DataFrames together. It’s interchangeably referred to as binding or stacking as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default axis \n",
      "     A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "4  A4  B4  C4  D4\n",
      "5  A5  B5  C5  D5\n",
      "6  A6  B6  C6  D6\n",
      "7  A7  B7  C7  D7\n",
      "Axis = 1 \n",
      "      A    B    C    D    A    B    C    D\n",
      "0   A0   B0   C0   D0  NaN  NaN  NaN  NaN\n",
      "1   A1   B1   C1   D1  NaN  NaN  NaN  NaN\n",
      "2   A2   B2   C2   D2  NaN  NaN  NaN  NaN\n",
      "3   A3   B3   C3   D3  NaN  NaN  NaN  NaN\n",
      "4  NaN  NaN  NaN  NaN   A4   B4   C4   D4\n",
      "5  NaN  NaN  NaN  NaN   A5   B5   C5   D5\n",
      "6  NaN  NaN  NaN  NaN   A6   B6   C6   D6\n",
      "7  NaN  NaN  NaN  NaN   A7   B7   C7   D7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                        'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                        'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                        'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                        index=[0, 1, 2, 3])\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                        'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                        'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                        'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                         index=[4,5,6,7])\n",
    "# the default axis is 0 'index' (rows) to concatenate along.\n",
    "print(\"Default axis \\n\",pd.concat([df1,df2]))\n",
    "\n",
    "# axis = 1 for columns\n",
    "print(\"Axis = 1 \\n\", pd.concat([df1,df2],axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GroupBy methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Store Customer  Sales\n",
      "0  Walmart      Tim    150\n",
      "1  Walmart    Jermy    200\n",
      "2   Costco     Mark    550\n",
      "3   Costco   Denice     90\n",
      "4   Target      Ray    430\n",
      "5   Target      Sam    120\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Create a DataFrame\n",
    "data = {'Store':['Walmart','Walmart','Costco','Costco','Target','Target'],\n",
    "       'Customer':['Tim','Jermy','Mark','Denice','Ray','Sam'],\n",
    "       'Sales':[150,200,550,90,430,120]}\n",
    "\n",
    "# Creating DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fa9d2e39f90>\n"
     ]
    }
   ],
   "source": [
    "# Let's create new grouped DataFrame \"by_store\" after grouping on \"store\" column\n",
    "by_store = df.groupby(\"Store\")\n",
    "print(by_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Sales\n",
      "Store         \n",
      "Costco   320.0\n",
      "Target   275.0\n",
      "Walmart  175.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14652/2287033011.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(by_store.mean())\n"
     ]
    }
   ],
   "source": [
    "print(by_store.mean())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales    550\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "Minimum value of sale \n",
      "         Customer  Sales\n",
      "Store                  \n",
      "Costco    Denice     90\n",
      "Target       Ray    120\n",
      "Walmart    Jermy    150\n",
      "\n",
      "Maximum value of sale \n",
      "         Customer  Sales\n",
      "Store                  \n",
      "Costco      Mark    550\n",
      "Target       Sam    430\n",
      "Walmart      Tim    200\n",
      "\n",
      "Standard deviation of sale \n",
      "               Sales\n",
      "Store              \n",
      "Costco   325.269119\n",
      "Target   219.203102\n",
      "Walmart   35.355339\n",
      "\n",
      "Count :           Customer  Sales\n",
      "Store                   \n",
      "Costco          2      2\n",
      "Target          2      2\n",
      "Walmart         2      2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14652/1686056223.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(df.groupby('Store').sum().loc[\"Target\"])\n",
      "/tmp/ipykernel_14652/1686056223.py:5: FutureWarning: The default value of numeric_only in DataFrameGroupBy.std is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(\"\\nStandard deviation of sale \\n\", by_store.std()) # standard deviation of sale\n"
     ]
    }
   ],
   "source": [
    "# In one line of code using sum ad loc methods\n",
    "print(df.groupby('Store').sum().loc[\"Target\"])\n",
    "print(\"\\nMinimum value of sale \\n\", by_store.min()) # minimum value of sale \n",
    "print(\"\\nMaximum value of sale \\n\", by_store.max()) # maximum value of sale \n",
    "print(\"\\nStandard deviation of sale \\n\", by_store.std()) # standard deviation of sale\n",
    "# Let's count the number of instances in each column, this operation works with strings as well\n",
    "# we have 2 customers for each store and 2 sales for each store\n",
    "print(\"\\nCount : \", by_store.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Sales                                                      \n",
      "        count   mean         std    min    25%    50%    75%    max\n",
      "Store                                                              \n",
      "Costco    2.0  320.0  325.269119   90.0  205.0  320.0  435.0  550.0\n",
      "Target    2.0  275.0  219.203102  120.0  197.5  275.0  352.5  430.0\n",
      "Walmart   2.0  175.0   35.355339  150.0  162.5  175.0  187.5  200.0\n",
      "\n",
      "Store            Costco      Target     Walmart\n",
      "Sales count    2.000000    2.000000    2.000000\n",
      "      mean   320.000000  275.000000  175.000000\n",
      "      std    325.269119  219.203102   35.355339\n",
      "      min     90.000000  120.000000  150.000000\n",
      "      25%    205.000000  197.500000  162.500000\n",
      "      50%    320.000000  275.000000  175.000000\n",
      "      75%    435.000000  352.500000  187.500000\n",
      "      max    550.000000  430.000000  200.000000\n",
      "\n",
      "Sales  count      2.000000\n",
      "       mean     320.000000\n",
      "       std      325.269119\n",
      "       min       90.000000\n",
      "       25%      205.000000\n",
      "       50%      320.000000\n",
      "       75%      435.000000\n",
      "       max      550.000000\n",
      "Name: Costco, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# summary statistics using describe on grouped DataFrame \n",
    "print(by_store.describe())\n",
    "print()\n",
    "# transpose after describe (two operations in one go!)\n",
    "print(by_store.describe().transpose() )\n",
    "print()\n",
    "# summary statistics for Costco \n",
    "print(by_store.describe().transpose()['Costco'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Store Customer  Sales\n",
      "0  Walmart      Tim    150\n",
      "1  Walmart    Jermy    200\n",
      "2   Costco     Mark    550\n",
      "3   Costco   Denice     90\n",
      "4   Target      Ray    430\n",
      "5   Target      Sam    120\n",
      "['Tim', 'Jermy', 'Mark', 'Ray', 'Sam']\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "customer_list = list(df[df['Sales'] > 100]['Customer'])\n",
    "print(customer_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
